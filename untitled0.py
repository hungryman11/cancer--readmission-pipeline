# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Af9ryDZEnJ6swxc5Dj40RrUtjx5Duu1M
"""

!pip install pyspark

from pyspark.sql import SparkSession
import sys

print(f"‚úÖ Python version: {sys.version}")

# Create Spark session
spark = SparkSession.builder \
    .appName("ColabTest") \
    .master("local[*]") \
    .config("spark.driver.memory", "4g") \
    .getOrCreate()

print(f"‚úÖ PySpark version: {spark.version}")
print("‚úÖ Spark session created successfully!")

# Create a simple test DataFrame
data = [
    ("Patient001", 65, 5, 1),
    ("Patient002", 45, 2, 0),
    ("Patient003", 78, 8, 1)
]
columns = ["patient_id", "age", "num_admissions", "readmitted"]

df = spark.createDataFrame(data, columns)

print("\n‚úÖ Test DataFrame created:")
df.show()

print("\n‚úÖ Basic operations work:")
df.groupBy("readmitted").count().show()

print("\nüéâ Everything is working! Ready for hospital readmission prediction!")

# Install additional helpful libraries
!pip install pandas numpy matplotlib scikit-learn pyarrow

"""
Hospital Readmission Prediction Pipeline - Google Colab Version
Complete beginner-friendly pipeline for predicting hospital readmissions
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, count, avg
from pyspark.ml.feature import VectorAssembler, StandardScaler
from pyspark.ml.classification import LogisticRegression, RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from pyspark.ml import Pipeline
import time

print("="*70)
print("üè• HOSPITAL READMISSION PREDICTION PIPELINE - GOOGLE COLAB")
print("="*70)

# ============================================================================
# STEP 1: Initialize Spark Session
# ============================================================================
print("\nüìç STEP 1: Initializing Spark Session")
print("-"*70)

spark = SparkSession.builder \
    .appName("HospitalReadmissionColab") \
    .master("local[*]") \
    .config("spark.driver.memory", "4g") \
    .config("spark.sql.shuffle.partitions", "4") \
    .getOrCreate()

print(f"‚úÖ Spark {spark.version} initialized")
print(f"   Memory allocated: 4GB")

# ============================================================================
# STEP 2: Create Sample Hospital Data
# ============================================================================
print("\nüìç STEP 2: Creating Sample Hospital Dataset")
print("-"*70)

# Create realistic sample hospital readmission data
from random import seed, randint, random, choice
seed(42)

# Generate 1000 sample patient records
num_patients = 1000
sample_data = []

for i in range(num_patients):
    patient_id = f"P{i+1:04d}"
    age = randint(20, 90)
    gender = choice([0, 1])  # 0=Female, 1=Male

    # Length of stay (days)
    length_of_stay = randint(1, 30)

    # Previous admissions (patients with more history at higher risk)
    previous_admissions = randint(0, 10)

    # Chronic conditions (increase readmission risk)
    has_diabetes = 1 if random() < 0.3 else 0
    has_heart_disease = 1 if random() < 0.25 else 0
    has_copd = 1 if random() < 0.2 else 0

    # Vitals (higher values = more risk)
    avg_heart_rate = randint(60, 120)
    avg_bp_systolic = randint(90, 180)

    # Lab values
    glucose_level = randint(70, 250)

    # Number of medications (more = complex case)
    num_medications = randint(0, 20)

    # Emergency admission (higher risk)
    emergency_admission = 1 if random() < 0.4 else 0

    # Calculate readmission probability based on risk factors
    readmission_prob = 0.1  # Base rate

    # Age increases risk
    if age > 65:
        readmission_prob += 0.15

    # Previous admissions strongly predict readmission
    readmission_prob += previous_admissions * 0.05

    # Chronic conditions increase risk
    readmission_prob += has_diabetes * 0.1
    readmission_prob += has_heart_disease * 0.12
    readmission_prob += has_copd * 0.08

    # Long stays indicate complexity
    if length_of_stay > 7:
        readmission_prob += 0.1

    # Many medications = complex patient
    if num_medications > 10:
        readmission_prob += 0.08

    # Emergency admissions have higher readmission
    readmission_prob += emergency_admission * 0.1

    # Determine readmission (add some randomness)
    readmitted = 1 if random() < min(readmission_prob, 0.8) else 0

    sample_data.append((
        patient_id, age, gender, length_of_stay, previous_admissions,
        has_diabetes, has_heart_disease, has_copd,
        avg_heart_rate, avg_bp_systolic, glucose_level,
        num_medications, emergency_admission, readmitted
    ))

# Define schema
columns = [
    "patient_id", "age", "gender", "length_of_stay", "previous_admissions",
    "has_diabetes", "has_heart_disease", "has_copd",
    "avg_heart_rate", "avg_bp_systolic", "glucose_level",
    "num_medications", "emergency_admission", "readmitted"
]

# Create DataFrame
df = spark.createDataFrame(sample_data, columns)

print(f"‚úÖ Created dataset with {df.count():,} patients")
print(f"   Features: {len(columns)-2} (excluding patient_id and readmitted)")

# ============================================================================
# STEP 3: Explore the Data
# ============================================================================
print("\nüìç STEP 3: Exploring the Data")
print("-"*70)

print("\nüìä First 10 patients:")
df.show(10, truncate=False)

print("\nüìä Basic Statistics:")
df.describe().select(
    "age", "length_of_stay", "previous_admissions",
    "num_medications", "readmitted"
).show()

print("\nüìä Readmission Rate:")
readmission_stats = df.groupBy("readmitted").count()
readmission_stats.show()

total = df.count()
readmitted_count = df.filter(col("readmitted") == 1).count()
readmission_rate = (readmitted_count / total) * 100
print(f"   Overall Readmission Rate: {readmission_rate:.1f}%")

print("\nüìä Readmission by Age Group:")
df.withColumn(
    "age_group",
    when(col("age") < 40, "Under 40")
    .when((col("age") >= 40) & (col("age") < 65), "40-64")
    .otherwise("65+")
).groupBy("age_group", "readmitted").count().show()

# ============================================================================
# STEP 4: Feature Engineering
# ============================================================================
print("\nüìç STEP 4: Engineering Features")
print("-"*70)

# Create additional features
df_engineered = df.withColumn(
    "age_risk",
    when(col("age") > 65, 1).otherwise(0)
).withColumn(
    "long_stay",
    when(col("length_of_stay") > 7, 1).otherwise(0)
).withColumn(
    "high_medications",
    when(col("num_medications") > 10, 1).otherwise(0)
).withColumn(
    "chronic_conditions_count",
    col("has_diabetes") + col("has_heart_disease") + col("has_copd")
).withColumn(
    "abnormal_glucose",
    when((col("glucose_level") > 200) | (col("glucose_level") < 70), 1).otherwise(0)
)

print("‚úÖ Created new features:")
print("   - age_risk: Patients over 65")
print("   - long_stay: Hospital stays > 7 days")
print("   - high_medications: More than 10 medications")
print("   - chronic_conditions_count: Total chronic conditions")
print("   - abnormal_glucose: Abnormal glucose levels")

# ============================================================================
# STEP 5: Prepare Data for Machine Learning
# ============================================================================
print("\nüìç STEP 5: Preparing ML Pipeline")
print("-"*70)

# Select features for modeling
feature_cols = [
    "age", "gender", "length_of_stay", "previous_admissions",
    "has_diabetes", "has_heart_disease", "has_copd",
    "avg_heart_rate", "avg_bp_systolic", "glucose_level",
    "num_medications", "emergency_admission",
    "age_risk", "long_stay", "high_medications",
    "chronic_conditions_count", "abnormal_glucose"
]

print(f"‚úÖ Using {len(feature_cols)} features for prediction")

# Assemble features
assembler = VectorAssembler(
    inputCols=feature_cols,
    outputCol="features_raw"
)

# Scale features
scaler = StandardScaler(
    inputCol="features_raw",
    outputCol="features",
    withStd=True,
    withMean=True
)

# Create preprocessing pipeline
prep_pipeline = Pipeline(stages=[assembler, scaler])
prep_model = prep_pipeline.fit(df_engineered)
df_prepared = prep_model.transform(df_engineered)

# Split data
train_data, test_data = df_prepared.randomSplit([0.8, 0.2], seed=42)

train_count = train_data.count()
test_count = test_data.count()

print(f"‚úÖ Data split complete:")
print(f"   Training set: {train_count:,} patients ({train_count/total*100:.0f}%)")
print(f"   Test set: {test_count:,} patients ({test_count/total*100:.0f}%)")

# ============================================================================
# STEP 6: Train Logistic Regression Model
# ============================================================================
print("\nüìç STEP 6: Training Logistic Regression")
print("-"*70)

lr_start = time.time()

lr = LogisticRegression(
    featuresCol="features",
    labelCol="readmitted",
    maxIter=100,
    regParam=0.01
)

print("üîÑ Training model...")
lr_model = lr.fit(train_data)
lr_time = time.time() - lr_start

print(f"‚úÖ Model trained in {lr_time:.2f} seconds")

# Make predictions
lr_predictions = lr_model.transform(test_data)

# ============================================================================
# STEP 7: Train Random Forest Model
# ============================================================================
print("\nüìç STEP 7: Training Random Forest")
print("-"*70)

rf_start = time.time()

rf = RandomForestClassifier(
    featuresCol="features",
    labelCol="readmitted",
    numTrees=100,
    maxDepth=10,
    seed=42
)

print("üîÑ Training model...")
rf_model = rf.fit(train_data)
rf_time = time.time() - rf_start

print(f"‚úÖ Model trained in {rf_time:.2f} seconds")

# Make predictions
rf_predictions = rf_model.transform(test_data)

# Show feature importance
print("\nüìä Top 10 Most Important Features:")
feature_importance = sorted(
    zip(feature_cols, rf_model.featureImportances),
    key=lambda x: x[1],
    reverse=True
)
for i, (feature, importance) in enumerate(feature_importance[:10], 1):
    print(f"   {i:2d}. {feature:30s} {importance:.4f}")

# ============================================================================
# STEP 8: Evaluate Models
# ============================================================================
print("\nüìç STEP 8: Evaluating Models")
print("-"*70)

def evaluate_model(predictions, model_name):
    """Evaluate model and return metrics"""

    # AUC-ROC
    auc_eval = BinaryClassificationEvaluator(
        labelCol="readmitted",
        metricName="areaUnderROC"
    )
    auc = auc_eval.evaluate(predictions)

    # Accuracy
    acc_eval = MulticlassClassificationEvaluator(
        labelCol="readmitted",
        predictionCol="prediction",
        metricName="accuracy"
    )
    accuracy = acc_eval.evaluate(predictions)

    # Precision
    prec_eval = MulticlassClassificationEvaluator(
        labelCol="readmitted",
        predictionCol="prediction",
        metricName="weightedPrecision"
    )
    precision = prec_eval.evaluate(predictions)

    # Recall
    rec_eval = MulticlassClassificationEvaluator(
        labelCol="readmitted",
        predictionCol="prediction",
        metricName="weightedRecall"
    )
    recall = rec_eval.evaluate(predictions)

    # F1 Score
    f1_eval = MulticlassClassificationEvaluator(
        labelCol="readmitted",
        predictionCol="prediction",
        metricName="f1"
    )
    f1 = f1_eval.evaluate(predictions)

    print(f"\nüéØ {model_name} Results:")
    print(f"   AUC-ROC:   {auc:.4f}")
    print(f"   Accuracy:  {accuracy:.4f}")
    print(f"   Precision: {precision:.4f}")
    print(f"   Recall:    {recall:.4f}")
    print(f"   F1-Score:  {f1:.4f}")

    print(f"\n   Confusion Matrix:")
    predictions.groupBy("readmitted", "prediction").count().show()

    return {
        'auc': auc,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }

lr_metrics = evaluate_model(lr_predictions, "LOGISTIC REGRESSION")
rf_metrics = evaluate_model(rf_predictions, "RANDOM FOREST")

# ============================================================================
# STEP 9: Compare Models
# ============================================================================
print("\nüìç STEP 9: Model Comparison")
print("="*70)

print(f"\n{'Metric':<15} {'Logistic Regression':<25} {'Random Forest':<25}")
print("-"*70)
print(f"{'AUC-ROC':<15} {lr_metrics['auc']:<25.4f} {rf_metrics['auc']:<25.4f}")
print(f"{'Accuracy':<15} {lr_metrics['accuracy']:<25.4f} {rf_metrics['accuracy']:<25.4f}")
print(f"{'Precision':<15} {lr_metrics['precision']:<25.4f} {rf_metrics['precision']:<25.4f}")
print(f"{'Recall':<15} {lr_metrics['recall']:<25.4f} {rf_metrics['recall']:<25.4f}")
print(f"{'F1-Score':<15} {lr_metrics['f1']:<25.4f} {rf_metrics['f1']:<25.4f}")
print(f"{'Training Time':<15} {lr_time:<25.2f}s {rf_time:<25.2f}s")

# Determine best model
if rf_metrics['auc'] > lr_metrics['auc']:
    print("\nüèÜ WINNER: Random Forest (Higher AUC)")
    best_model = "Random Forest"
else:
    print("\nüèÜ WINNER: Logistic Regression (Higher AUC)")
    best_model = "Logistic Regression"

# ============================================================================
# STEP 10: Make Sample Predictions
# ============================================================================
print("\nüìç STEP 10: Making Predictions on New Patients")
print("-"*70)

# Show some example predictions
print("\nüîç Sample Predictions (First 10 test patients):")
sample_predictions = rf_predictions.select(
    "patient_id", "age", "previous_admissions",
    "chronic_conditions_count", "readmitted", "prediction", "probability"
).limit(10)

sample_predictions.show(truncate=False)

# ============================================================================
# SUMMARY
# ============================================================================
print("\n" + "="*70)
print("‚úÖ PIPELINE COMPLETED SUCCESSFULLY!")
print("="*70)
print(f"\nüìä Summary:")
print(f"   Dataset: {total:,} patients")
print(f"   Features: {len(feature_cols)}")
print(f"   Models Trained: 2 (Logistic Regression, Random Forest)")
print(f"   Best Model: {best_model}")
print(f"   Best AUC: {max(lr_metrics['auc'], rf_metrics['auc']):.4f}")
print(f"\nüí° Next Steps:")
print(f"   1. Get real MIMIC-III data from https://physionet.org")
print(f"   2. Experiment with feature engineering")
print(f"   3. Try XGBoost or Gradient Boosted Trees")
print(f"   4. Tune hyperparameters")
print(f"   5. Deploy model for real-time predictions")

print("\n" + "="*70)

# Stop Spark session
spark.stop()
print("üõë Spark session stopped")

# Upload your cleaned data
from google.colab import files
import pandas as pd

print("üì§ Please upload your cleaned cancer patient data...")
uploaded = files.upload()

# Get the filename
filename = list(uploaded.keys())[0]
print(f"‚úÖ Uploaded: {filename}")

# Preview the data with pandas first
df_preview = pd.read_excel(filename, engine='openpyxl')
print(f"\nüìä Dataset Shape: {df_preview.shape[0]:,} rows √ó {df_preview.shape[1]} columns")
print(f"\nüìã Column Names:")
print(df_preview.columns.tolist())
print(f"\nüëÄ First 5 rows:")
print(df_preview.head())
print(f"\nüìà Data Types:")
print(df_preview.dtypes)
print(f"\n‚ùì Missing Values:")
print(df_preview.isnull().sum())

!pip install openpyxl

from imblearn.over_sampling import SMOTE

from sklearn.datasets import make_classification
import pandas as pd

X, y = make_classification(n_samples=10000, n_features=20,
                           weights=[0.85, 0.15], random_state=42)

df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(20)])
df['readmitted_30days'] = y

print(f"‚úÖ Generated {len(df):,} synthetic patients")

"""
Cancer Patient Readmission Prediction System
Complete end-to-end pipeline using PySpark MLlib

This pipeline handles:
1. Data loading and validation
2. EHR-specific feature engineering for cancer patients
3. Multiple ML models (Logistic Regression, Random Forest, GBT)
4. Comprehensive evaluation and visualization
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import (
    col, when, datediff, count, avg, sum as spark_sum,
    max as spark_max, min as spark_min, lit, year, month,
    lag, lead, desc, asc, round as spark_round
)
from pyspark.sql.window import Window
from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer
from pyspark.ml.classification import (
    LogisticRegression,
    RandomForestClassifier,
    GBTClassifier
)
from pyspark.ml.evaluation import (
    BinaryClassificationEvaluator,
    MulticlassClassificationEvaluator
)
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.ml import Pipeline
import time
from datetime import datetime

# ============================================================================
# CONFIGURATION
# ============================================================================

class Config:
    """Configuration parameters for the pipeline"""

    # File paths (UPDATE THESE with your actual file names)
    DATA_PATH = "your_cleaned_data.csv"  # CHANGE THIS

    # Target variable
    TARGET_COLUMN = "readmitted_30days"  # CHANGE THIS to your readmission column

    # Patient identifier
    PATIENT_ID = "patient_id"  # CHANGE THIS

    # Date columns (if available)
    ADMIT_DATE = "admission_date"  # CHANGE THIS or set to None
    DISCHARGE_DATE = "discharge_date"  # CHANGE THIS or set to None

    # Cancer-specific columns (adjust based on your data)
    CANCER_TYPE = "cancer_type"
    CANCER_STAGE = "cancer_stage"

    # Model parameters
    TRAIN_TEST_SPLIT = [0.8, 0.2]
    RANDOM_SEED = 42
    CROSS_VALIDATION_FOLDS = 3

# ============================================================================
# STEP 1: INITIALIZE SPARK SESSION
# ============================================================================

def initialize_spark():
    """Create and configure Spark session"""
    print("="*80)
    print("üè• CANCER PATIENT READMISSION PREDICTION SYSTEM")
    print("="*80)
    print("\nüìç STEP 1: Initializing Apache Spark")
    print("-"*80)

    spark = SparkSession.builder \
        .appName("CancerReadmissionPrediction") \
        .master("local[*]") \
        .config("spark.driver.memory", "8g") \
        .config("spark.sql.shuffle.partitions", "8") \
        .config("spark.sql.adaptive.enabled", "true") \
        .getOrCreate()

    spark.sparkContext.setLogLevel("WARN")

    print(f"‚úÖ Spark {spark.version} initialized successfully")
    print(f"   Memory: 8GB")
    print(f"   Cores: All available")

    return spark

# ============================================================================
# STEP 2: DATA LOADING AND VALIDATION
# ============================================================================

def load_and_validate_data(spark, filepath):
    """Load data from CSV and perform initial validation"""
    print("\nüìç STEP 2: Loading and Validating Data")
    print("-"*80)

    try:
        # Load data
        df = spark.read.csv(filepath, header=True, inferSchema=True)

        row_count = df.count()
        col_count = len(df.columns)

        print(f"‚úÖ Data loaded successfully")
        print(f"   Rows: {row_count:,}")
        print(f"   Columns: {col_count}")

        # Show schema
        print("\nüìã Data Schema:")
        df.printSchema()

        # Check for missing values
        print("\nüîç Missing Value Analysis:")
        missing_counts = df.select([
            count(when(col(c).isNull(), c)).alias(c)
            for c in df.columns
        ])

        # Convert to pandas for better display
        missing_df = missing_counts.toPandas().T
        missing_df.columns = ['Missing Count']
        missing_df['Missing %'] = (missing_df['Missing Count'] / row_count * 100).round(2)
        missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)

        if len(missing_df) > 0:
            print(missing_df.to_string())
        else:
            print("   ‚úÖ No missing values detected!")

        # Show sample data
        print("\nüëÄ First 10 rows:")
        df.show(10, truncate=False)

        return df

    except Exception as e:
        print(f"‚ùå Error loading data: {e}")
        raise

# ============================================================================
# STEP 3: CANCER-SPECIFIC FEATURE ENGINEERING
# ============================================================================

def engineer_cancer_features(df, config):
    """Create cancer-specific features for readmission prediction"""
    print("\nüìç STEP 3: Engineering Cancer-Specific Features")
    print("-"*80)

    feature_count = 0

    # 1. PATIENT DEMOGRAPHICS FEATURES
    print("\nüîß Creating demographic features...")

    # Age risk groups
    if 'age' in df.columns:
        df = df.withColumn('age_risk_group',
            when(col('age') < 50, 'young')
            .when((col('age') >= 50) & (col('age') < 65), 'middle')
            .otherwise('elderly')
        ).withColumn('is_elderly',
            when(col('age') >= 65, 1).otherwise(0)
        )
        feature_count += 2

    # 2. CANCER CHARACTERISTICS FEATURES
    print("üîß Creating cancer characteristic features...")

    # Advanced stage indicator
    if config.CANCER_STAGE in df.columns:
        df = df.withColumn('is_advanced_stage',
            when(col(config.CANCER_STAGE).isin(['Stage III', 'Stage IV', 'III', 'IV', '3', '4']), 1)
            .otherwise(0)
        )
        feature_count += 1

    # Metastatic indicator (if available)
    if 'metastasis' in df.columns or 'metastatic' in df.columns:
        meta_col = 'metastasis' if 'metastasis' in df.columns else 'metastatic'
        df = df.withColumn('has_metastasis',
            when(col(meta_col) == 1, 1).otherwise(0)
        )
        feature_count += 1

    # 3. TREATMENT FEATURES
    print("üîß Creating treatment history features...")

    # Chemotherapy indicators
    if 'chemotherapy' in df.columns or 'chemo_cycles' in df.columns:
        if 'chemo_cycles' in df.columns:
            df = df.withColumn('has_chemotherapy',
                when(col('chemo_cycles') > 0, 1).otherwise(0)
            ).withColumn('intensive_chemo',
                when(col('chemo_cycles') >= 6, 1).otherwise(0)
            )
            feature_count += 2
        else:
            df = df.withColumn('has_chemotherapy',
                when(col('chemotherapy') == 1, 1).otherwise(0)
            )
            feature_count += 1

    # Radiation therapy
    if 'radiation' in df.columns:
        df = df.withColumn('has_radiation',
            when(col('radiation') == 1, 1).otherwise(0)
        )
        feature_count += 1

    # Surgery
    if 'surgery' in df.columns:
        df = df.withColumn('has_surgery',
            when(col('surgery') == 1, 1).otherwise(0)
        )
        feature_count += 1

    # 4. ADMISSION PATTERN FEATURES
    print("üîß Creating admission pattern features...")

    # Previous admissions
    if 'previous_admissions' in df.columns:
        df = df.withColumn('frequent_admitter',
            when(col('previous_admissions') >= 3, 1).otherwise(0)
        )
        feature_count += 1

    # Length of stay
    if 'length_of_stay' in df.columns:
        df = df.withColumn('prolonged_stay',
            when(col('length_of_stay') > 7, 1).otherwise(0)
        ).withColumn('very_long_stay',
            when(col('length_of_stay') > 14, 1).otherwise(0)
        )
        feature_count += 2
    elif config.ADMIT_DATE and config.DISCHARGE_DATE:
        # Calculate LOS from dates
        df = df.withColumn('length_of_stay',
            datediff(col(config.DISCHARGE_DATE), col(config.ADMIT_DATE))
        ).withColumn('prolonged_stay',
            when(col('length_of_stay') > 7, 1).otherwise(0)
        )
        feature_count += 2

    # Emergency admission
    if 'admission_type' in df.columns:
        df = df.withColumn('emergency_admission',
            when(col('admission_type').isin(['Emergency', 'emergency', 'EMERGENCY']), 1)
            .otherwise(0)
        )
        feature_count += 1

    # ICU stay
    if 'icu_stay' in df.columns or 'icu_admission' in df.columns:
        icu_col = 'icu_stay' if 'icu_stay' in df.columns else 'icu_admission'
        df = df.withColumn('had_icu_stay',
            when(col(icu_col) == 1, 1).otherwise(0)
        )
        feature_count += 1

    # 5. CLINICAL INDICATORS
    print("üîß Creating clinical indicator features...")

    # Lab value flags (common cancer-related labs)
    lab_features = {
        'wbc': ('low_wbc', lambda x: x < 4.0),  # Neutropenia risk
        'hemoglobin': ('anemia', lambda x: x < 10.0),  # Anemia
        'platelets': ('thrombocytopenia', lambda x: x < 100),  # Low platelets
        'creatinine': ('renal_dysfunction', lambda x: x > 1.5),  # Kidney issues
        'albumin': ('hypoalbuminemia', lambda x: x < 3.5),  # Malnutrition
    }

    for lab_col, (feature_name, condition) in lab_features.items():
        if lab_col in df.columns:
            # Handle condition based on operation
            if 'low' in feature_name or 'hypo' in feature_name or lab_col in ['hemoglobin', 'platelets', 'albumin']:
                df = df.withColumn(feature_name,
                    when(col(lab_col) < condition.__code__.co_consts[1], 1).otherwise(0)
                )
            else:  # High values
                df = df.withColumn(feature_name,
                    when(col(lab_col) > condition.__code__.co_consts[1], 1).otherwise(0)
                )
            feature_count += 1

    # Weight loss indicator
    if 'weight_loss_percent' in df.columns:
        df = df.withColumn('significant_weight_loss',
            when(col('weight_loss_percent') >= 10, 1).otherwise(0)
        )
        feature_count += 1

    # 6. COMORBIDITY FEATURES
    print("üîß Creating comorbidity features...")

    comorbidities = ['diabetes', 'heart_disease', 'copd', 'kidney_disease',
                     'depression', 'hypertension']

    comorbidity_cols = [c for c in comorbidities if c in df.columns]

    if comorbidity_cols:
        # Count total comorbidities
        df = df.withColumn('comorbidity_count',
            sum([col(c) for c in comorbidity_cols])
        ).withColumn('multiple_comorbidities',
            when(col('comorbidity_count') >= 2, 1).otherwise(0)
        )
        feature_count += 2

    # 7. MEDICATION FEATURES
    print("üîß Creating medication features...")

    if 'num_medications' in df.columns:
        df = df.withColumn('polypharmacy',
            when(col('num_medications') >= 10, 1).otherwise(0)
        )
        feature_count += 1

    # Pain medication
    if 'pain_medication' in df.columns:
        df = df.withColumn('on_pain_meds',
            when(col('pain_medication') == 1, 1).otherwise(0)
        )
        feature_count += 1

    # 8. SOCIAL DETERMINANTS
    print("üîß Creating social determinant features...")

    if 'discharge_disposition' in df.columns:
        df = df.withColumn('discharged_to_facility',
            when(col('discharge_disposition').isin(['SNF', 'Rehab', 'facility']), 1)
            .otherwise(0)
        )
        feature_count += 1

    # 9. COMPOSITE RISK SCORES
    print("üîß Creating composite risk scores...")

    # Create a simple risk score based on available features
    risk_components = []

    if 'is_elderly' in [c.name for c in df.schema]:
        risk_components.append('is_elderly')
    if 'is_advanced_stage' in [c.name for c in df.schema]:
        risk_components.append('is_advanced_stage')
    if 'emergency_admission' in [c.name for c in df.schema]:
        risk_components.append('emergency_admission')
    if 'multiple_comorbidities' in [c.name for c in df.schema]:
        risk_components.append('multiple_comorbidities')

    if risk_components:
        df = df.withColumn('composite_risk_score',
            sum([col(c) for c in risk_components])
        ).withColumn('high_risk_patient',
            when(col('composite_risk_score') >= 2, 1).otherwise(0)
        )
        feature_count += 2

    print(f"\n‚úÖ Feature engineering complete!")
    print(f"   Created {feature_count} new features")
    print(f"   Total columns: {len(df.columns)}")

    return df

# ============================================================================
# STEP 4: PREPARE DATA FOR MACHINE LEARNING
# ============================================================================

def prepare_ml_data(df, config):
    """Prepare features for machine learning models"""
    print("\nüìç STEP 4: Preparing Data for Machine Learning")
    print("-"*80)

    # Identify feature columns (exclude ID, target, and date columns)
    exclude_cols = [
        config.PATIENT_ID,
        config.TARGET_COLUMN,
        config.ADMIT_DATE,
        config.DISCHARGE_DATE,
        'age_risk_group'  # categorical, not numeric
    ]
    exclude_cols = [c for c in exclude_cols if c is not None]

    # Get numeric feature columns
    numeric_cols = [c.name for c in df.schema.fields
                    if c.dataType.simpleString() in ['int', 'double', 'long', 'float']
                    and c.name not in exclude_cols]

    print(f"\nüìä Feature Selection:")
    print(f"   Total features: {len(numeric_cols)}")
    print(f"   Features: {numeric_cols[:10]}{'...' if len(numeric_cols) > 10 else ''}")

    # Handle missing values
    print(f"\nüîß Handling missing values...")
    df_clean = df.na.fill(0, subset=numeric_cols)  # Fill numeric nulls with 0

    # Verify target variable exists
    if config.TARGET_COLUMN not in df_clean.columns:
        raise ValueError(f"Target column '{config.TARGET_COLUMN}' not found in data!")

    # Check class distribution
    print(f"\nüìä Target Variable Distribution:")
    df_clean.groupBy(config.TARGET_COLUMN).count().show()

    # Assemble features
    assembler = VectorAssembler(
        inputCols=numeric_cols,
        outputCol="features_raw",
        handleInvalid="skip"
    )

    # Scale features
    scaler = StandardScaler(
        inputCol="features_raw",
        outputCol="features",
        withStd=True,
        withMean=True
    )

    # Create pipeline
    prep_pipeline = Pipeline(stages=[assembler, scaler])
    prep_model = prep_pipeline.fit(df_clean)
    df_prepared = prep_model.transform(df_clean)

    # Split data
    train_data, test_data = df_prepared.randomSplit(
        config.TRAIN_TEST_SPLIT,
        seed=config.RANDOM_SEED
    )

    train_count = train_data.count()
    test_count = test_data.count()

    print(f"\n‚úÖ Data preparation complete!")
    print(f"   Training set: {train_count:,} samples")
    print(f"   Test set: {test_count:,} samples")

    return train_data, test_data, numeric_cols, prep_model

# ============================================================================
# STEP 5: TRAIN MACHINE LEARNING MODELS
# ============================================================================

def train_models(train_data, test_data, config):
    """Train multiple ML models and return predictions"""
    print("\nüìç STEP 5: Training Machine Learning Models")
    print("-"*80)

    models = {}
    predictions = {}
    training_times = {}

    # 1. LOGISTIC REGRESSION
    print("\nü§ñ Training Logistic Regression...")
    start_time = time.time()

    lr = LogisticRegression(
        featuresCol="features",
        labelCol=config.TARGET_COLUMN,
        maxIter=100,
        regParam=0.01,
        elasticNetParam=0.1
    )

    lr_model = lr.fit(train_data)
    lr_pred = lr_model.transform(test_data)

    models['Logistic Regression'] = lr_model
    predictions['Logistic Regression'] = lr_pred
    training_times['Logistic Regression'] = time.time() - start_time

    print(f"   ‚úÖ Trained in {training_times['Logistic Regression']:.2f}s")

    # 2. RANDOM FOREST
    print("\nüå≤ Training Random Forest...")
    start_time = time.time()

    rf = RandomForestClassifier(
        featuresCol="features",
        labelCol=config.TARGET_COLUMN,
        numTrees=100,
        maxDepth=10,
        minInstancesPerNode=5,
        seed=config.RANDOM_SEED
    )

    rf_model = rf.fit(train_data)
    rf_pred = rf_model.transform(test_data)

    models['Random Forest'] = rf_model
    predictions['Random Forest'] = rf_pred
    training_times['Random Forest'] = time.time() - start_time

    print(f"   ‚úÖ Trained in {training_times['Random Forest']:.2f}s")

    # 3. GRADIENT BOOSTED TREES
    print("\nüöÄ Training Gradient Boosted Trees...")
    start_time = time.time()

    gbt = GBTClassifier(
        featuresCol="features",
        labelCol=config.TARGET_COLUMN,
        maxIter=50,
        maxDepth=5,
        seed=config.RANDOM_SEED
    )

    gbt_model = gbt.fit(train_data)
    gbt_pred = gbt_model.transform(test_data)

    models['Gradient Boosted Trees'] = gbt_model
    predictions['Gradient Boosted Trees'] = gbt_pred
    training_times['Gradient Boosted Trees'] = time.time() - start_time

    print(f"   ‚úÖ Trained in {training_times['Gradient Boosted Trees']:.2f}s")

    return models, predictions, training_times

# ============================================================================
# STEP 6: EVALUATE MODELS
# ============================================================================

def evaluate_models(predictions, config):
    """Evaluate all models and return metrics"""
    print("\nüìç STEP 6: Evaluating Models")
    print("-"*80)

    results = {}

    auc_eval = BinaryClassificationEvaluator(
        labelCol=config.TARGET_COLUMN,
        metricName="areaUnderROC"
    )

    acc_eval = MulticlassClassificationEvaluator(
        labelCol=config.TARGET_COLUMN,
        predictionCol="prediction",
        metricName="accuracy"
    )

    prec_eval = MulticlassClassificationEvaluator(
        labelCol=config.TARGET_COLUMN,
        predictionCol="prediction",
        metricName="weightedPrecision"
    )

    rec_eval = MulticlassClassificationEvaluator(
        labelCol=config.TARGET_COLUMN,
        predictionCol="prediction",
        metricName="weightedRecall"
    )

    f1_eval = MulticlassClassificationEvaluator(
        labelCol=config.TARGET_COLUMN,
        predictionCol="prediction",
        metricName="f1"
    )

    for model_name, pred in predictions.items():
        print(f"\nüìä {model_name}")
        print("-" * 50)

        metrics = {
            'auc': auc_eval.evaluate(pred),
            'accuracy': acc_eval.evaluate(pred),
            'precision': prec_eval.evaluate(pred),
            'recall': rec_eval.evaluate(pred),
            'f1': f1_eval.evaluate(pred)
        }

        print(f"   AUC-ROC:   {metrics['auc']:.4f}")
        print(f"   Accuracy:  {metrics['accuracy']:.4f}")
        print(f"   Precision: {metrics['precision']:.4f}")
        print(f"   Recall:    {metrics['recall']:.4f}")
        print(f"   F1-Score:  {metrics['f1']:.4f}")

        # Confusion matrix
        print(f"\n   Confusion Matrix:")
        pred.groupBy(config.TARGET_COLUMN, "prediction").count().show()

        results[model_name] = metrics

    return results

# ============================================================================
# STEP 7: MODEL COMPARISON I GUESS
# ============================================================================

def compare_models(results, training_times):
    """Compare all models and select best"""
    print("\nüìç STEP 7: Model Comparison")
    print("="*80)

    # Create comparison table
    print(f"\n{'Model':<30} {'AUC':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1':<10} {'Time(s)':<10}")
    print("-"*100)

    best_auc = 0
    best_model = None

    for model_name in results.keys():
        metrics = results[model_name]
        train_time = training_times[model_name]

        print(f"{model_name:<30} "
              f"{metrics['auc']:<10.4f} "
              f"{metrics['accuracy']:<10.4f} "
              f"{metrics['precision']:<10.4f} "
              f"{metrics['recall']:<10.4f} "
              f"{metrics['f1']:<10.4f} "
              f"{train_time:<10.2f}")

        if metrics['auc'] > best_auc:
            best_auc = metrics['auc']
            best_model = model_name

    print("\n" + "="*80)
    print(f"üèÜ BEST MODEL: {best_model} (AUC = {best_auc:.4f})")
    print("="*80)

    return best_model

# ============================================================================
# MAIN PIPELINE:I DON'T KNOW WHAT HAPPENS AFTER HERE
# ============================================================================

def main():
    """Execute complete cancer readmission prediction pipeline"""

    start_time = time.time()

    try:
        # Initialize
        config = Config()
        spark = initialize_spark()

        # Load data
        df = load_and_validate_data(spark, config.DATA_PATH)

        # Feature engineering
        df = engineer_cancer_features(df, config)

        # Prepare ML data
        train_data, test_data, feature_cols, prep_model = prepare_ml_data(df, config)

        # Train models
        models, predictions, training_times = train_models(train_data, test_data, config)

        # Evaluate
        results = evaluate_models(predictions, config)

        # Compare
        best_model = compare_models(results, training_times)

        # Summary
        total_time = time.time() - start_time
        print(f"\n{'='*80}")
        print(f"‚úÖ PIPELINE COMPLETED SUCCESSFULLY!")
        print(f"{'='*80}")
        print(f"   Total runtime: {total_time:.2f} seconds")
        print(f"   Best model: {best_model}")
        print(f"   Best AUC: {results[best_model]['auc']:.4f}")
        print(f"\nüí° Next Steps:")
        print(f"   1. Review feature importance")
        print(f"   2. Analyze misclassified cases")
        print(f"   3. Tune hyperparameters")
        print(f"   4. Validate on external dataset")
        print(f"   5. Deploy for clinical use")

    except Exception as e:
        print(f"\n‚ùå Pipeline failed: {e}")
        import traceback
        traceback.print_exc()

    finally:
        spark.stop()
        print(f"\nüõë Spark session stopped")

if __name__ == "__main__":
    main()

import pandas as pd
import numpy as np
from sklearn.datasets import make_classification

# Base separable features + target
X, y = make_classification(n_samples=10000, n_features=20,
                           weights=[0.85, 0.15], random_state=42, flip_y=0.05)

df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(20)])
df['readmitted_30days'] = y

# Add realistic columns
np.random.seed(42)

df['patient_id'] = range(1, len(df) + 1)
df['age'] = np.random.normal(65, 12, len(df)).clip(18, 90).astype(int)
df['cancer_stage'] = np.random.choice(['Stage I', 'Stage II', 'Stage III', 'Stage IV'],
                                      size=len(df), p=[0.25, 0.35, 0.25, 0.15])
df['cancer_type'] = np.random.choice(['Breast', 'Lung', 'Colorectal', 'Prostate', 'Pancreatic', 'Other'],
                                     size=len(df), p=[0.2, 0.2, 0.15, 0.15, 0.1, 0.2])
df['chemotherapy'] = np.random.choice([0, 1], size=len(df), p=[0.4, 0.6])
df['chemo_cycles'] = np.where(df['chemotherapy'] == 1, np.random.poisson(4, len(df)), 0)
df['radiation'] = np.random.choice([0, 1], size=len(df), p=[0.5, 0.5])
df['surgery'] = np.random.choice([0, 1], size=len(df), p=[0.3, 0.7])
df['previous_admissions'] = np.random.poisson(1.5, len(df))
df['length_of_stay'] = np.random.lognormal(mean=1.8, sigma=0.7, size=len(df)).astype(int) + 1
df['admission_type'] = np.random.choice(['Elective', 'Emergency', 'Urgent'], size=len(df), p=[0.4, 0.4, 0.2])
df['icu_stay'] = np.random.choice([0, 1], size=len(df), p=[0.8, 0.2])

# Labs
df['wbc'] = np.random.normal(7, 3, len(df)).clip(0.5, 20)
df['hemoglobin'] = np.random.normal(12, 2, len(df)).clip(6, 18)
df['platelets'] = np.random.normal(250, 80, len(df)).clip(10, 600)
df['creatinine'] = np.random.normal(1.0, 0.4, len(df)).clip(0.3, 10)
df['albumin'] = np.random.normal(4.0, 0.6, len(df)).clip(2, 5.5)

df['weight_loss_percent'] = np.random.gamma(2, 3, len(df)).clip(0, 30)

# Comorbidities
comorbs = ['diabetes', 'heart_disease', 'copd', 'kidney_disease', 'hypertension']
for c in comorbs:
    p = np.random.uniform(0.1, 0.4)
    df[c] = np.random.choice([0, 1], size=len(df), p=[1-p, p])

df['num_medications'] = np.random.poisson(8, len(df)) + 1
df['pain_medication'] = np.random.choice([0, 1], size=len(df), p=[0.3, 0.7])
df['discharge_disposition'] = np.random.choice(['Home', 'SNF', 'Rehab', 'Hospice', 'Other'],
                                              size=len(df), p=[0.6, 0.15, 0.15, 0.05, 0.05])

# Boost correlation for readmitted patients
high_risk = df['readmitted_30days'] == 1
df.loc[high_risk, 'age'] = (df.loc[high_risk, 'age'] + np.random.normal(10, 5, high_risk.sum())).clip(18, 90).astype(int)
df.loc[high_risk, 'length_of_stay'] += np.random.poisson(5, high_risk.sum())
df.loc[high_risk, 'previous_admissions'] += np.random.poisson(3, high_risk.sum())
df.loc[high_risk, 'num_medications'] += np.random.poisson(5, high_risk.sum())
df.loc[high_risk, ['wbc', 'creatinine']] += np.random.normal(2, 1, high_risk.sum() * 2).reshape(high_risk.sum(), 2)
df.loc[high_risk, ['hemoglobin', 'albumin']] -= np.random.normal(1, 0.5, high_risk.sum() * 2).reshape(high_risk.sum(), 2)

# Save
df.to_csv('cancer_readmission_synthetic.csv', index=False)
print("‚úÖ Synthetic dataset created: 'cancer_readmission_synthetic.csv'")
print(f"   Rows: {len(df):,} | Columns: {len(df.columns)} | Readmission rate: {df['readmitted_30days'].mean():.2%}")

class Config:
    """Configuration parameters for the pipeline"""

    # Updated path to the synthetic file you just created
    DATA_PATH = "cancer_readmission_synthetic.csv"  # <-- This matches the saved file

    # Target variable
    TARGET_COLUMN = "readmitted_30days"

    # Patient identifier (now present)
    PATIENT_ID = "patient_id"

    # Date columns (not in synthetic data)
    ADMIT_DATE = None
    DISCHARGE_DATE = None

    # Cancer-specific columns
    CANCER_TYPE = "cancer_type"
    CANCER_STAGE = "cancer_stage"

    # Model parameters
    TRAIN_TEST_SPLIT = [0.8, 0.2]
    RANDOM_SEED = 42
    CROSS_VALIDATION_FOLDS = 3

"""
Cancer Readmission Prediction - Visualization Suite
Comprehensive visualizations for model evaluation and insights

Run this AFTER the main pipeline to create visualizations
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix

# Set style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

# ============================================================================
# VISUALIZATION 1: MODEL PERFORMANCE COMPARISON
# ============================================================================

def plot_model_comparison(results, training_times):
    """Create comprehensive model comparison visualization"""

    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('üè• Cancer Readmission Model Comparison',
                 fontsize=16, fontweight='bold', y=0.995)

    models = list(results.keys())

    # Subplot 1: AUC Comparison
    ax = axes[0, 0]
    auc_scores = [results[m]['auc'] for m in models]
    colors = ['#2ecc71' if score == max(auc_scores) else '#3498db' for score in auc_scores]
    bars = ax.bar(models, auc_scores, color=colors, alpha=0.7, edgecolor='black')
    ax.set_ylabel('AUC-ROC Score', fontweight='bold')
    ax.set_title('AUC-ROC Comparison', fontweight='bold')
    ax.set_ylim([0.5, 1.0])
    ax.axhline(y=0.75, color='red', linestyle='--', alpha=0.5, label='Good threshold')
    ax.legend()

    # Add value labels on bars
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}',
                ha='center', va='bottom', fontweight='bold')

    # Subplot 2: All Metrics Comparison
    ax = axes[0, 1]
    metrics = ['accuracy', 'precision', 'recall', 'f1']
    x = np.arange(len(models))
    width = 0.2

    for i, metric in enumerate(metrics):
        values = [results[m][metric] for m in models]
        ax.bar(x + i*width, values, width, label=metric.capitalize(), alpha=0.8)

    ax.set_ylabel('Score', fontweight='bold')
    ax.set_title('All Metrics Comparison', fontweight='bold')
    ax.set_xticks(x + width * 1.5)
    ax.set_xticklabels(models, rotation=15, ha='right')
    ax.legend()
    ax.set_ylim([0, 1])
    ax.grid(axis='y', alpha=0.3)

    # Subplot 3: Training Time
    ax = axes[1, 0]
    times = [training_times[m] for m in models]
    bars = ax.bar(models, times, color='#e74c3c', alpha=0.7, edgecolor='black')
    ax.set_ylabel('Training Time (seconds)', fontweight='bold')
    ax.set_title('Training Time Comparison', fontweight='bold')

    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.2f}s',
                ha='center', va='bottom', fontweight='bold')

    # Subplot 4: Performance-Speed Trade-off
    ax = axes[1, 1]
    auc_scores = [results[m]['auc'] for m in models]
    times = [training_times[m] for m in models]

    scatter = ax.scatter(times, auc_scores, s=300, alpha=0.6,
                        c=['#2ecc71', '#3498db', '#e67e22'], edgecolor='black', linewidth=2)

    for i, model in enumerate(models):
        ax.annotate(model, (times[i], auc_scores[i]),
                   fontsize=9, ha='center', va='center', fontweight='bold')

    ax.set_xlabel('Training Time (seconds)', fontweight='bold')
    ax.set_ylabel('AUC-ROC Score', fontweight='bold')
    ax.set_title('Performance vs Speed Trade-off', fontweight='bold')
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("‚úÖ Saved: model_comparison.png")

# ============================================================================
# VISUALIZATION 2: ROC CURVES
# ============================================================================

def plot_roc_curves(predictions_dict, target_col):
    """Plot ROC curves for all models"""

    plt.figure(figsize=(12, 10))

    colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12', '#9b59b6']

    for i, (model_name, pred_df) in enumerate(predictions_dict.items()):
        # Convert to pandas for sklearn
        pred_pd = pred_df.select(target_col, 'probability').toPandas()

        # Extract probability of positive class
        y_true = pred_pd[target_col].values
        y_score = pred_pd['probability'].apply(lambda x: float(x[1])).values

        # Calculate ROC curve
        fpr, tpr, _ = roc_curve(y_true, y_score)
        roc_auc = auc(fpr, tpr)

        # Plot
        plt.plot(fpr, tpr, color=colors[i], lw=3,
                label=f'{model_name} (AUC = {roc_auc:.3f})')

    # Plot diagonal
    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier', alpha=0.5)

    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate', fontsize=14, fontweight='bold')
    plt.ylabel('True Positive Rate', fontsize=14, fontweight='bold')
    plt.title('üéØ ROC Curves - Cancer Readmission Prediction',
             fontsize=16, fontweight='bold')
    plt.legend(loc="lower right", fontsize=12, framealpha=0.9)
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("‚úÖ Saved: roc_curves.png")

# ============================================================================
# VISUALIZATION 3: PRECISION-RECALL CURVES
# ============================================================================

def plot_precision_recall_curves(predictions_dict, target_col):
    """Plot precision-recall curves for all models"""

    plt.figure(figsize=(12, 10))

    colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12', '#9b59b6']

    for i, (model_name, pred_df) in enumerate(predictions_dict.items()):
        # Convert to pandas
        pred_pd = pred_df.select(target_col, 'probability').toPandas()

        y_true = pred_pd[target_col].values
        y_score = pred_pd['probability'].apply(lambda x: float(x[1])).values

        # Calculate precision-recall curve
        precision, recall, _ = precision_recall_curve(y_true, y_score)

        # Plot
        plt.plot(recall, precision, color=colors[i], lw=3,
                label=f'{model_name}')

    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('Recall (Sensitivity)', fontsize=14, fontweight='bold')
    plt.ylabel('Precision (PPV)', fontsize=14, fontweight='bold')
    plt.title('üìä Precision-Recall Curves - Cancer Readmission',
             fontsize=16, fontweight='bold')
    plt.legend(loc="best", fontsize=12, framealpha=0.9)
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('precision_recall_curves.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("‚úÖ Saved: precision_recall_curves.png")

# ============================================================================
# VISUALIZATION 4: CONFUSION MATRICES
# ============================================================================

def plot_confusion_matrices(predictions_dict, target_col):
    """Plot confusion matrices for all models"""

    n_models = len(predictions_dict)
    fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 5))

    if n_models == 1:
        axes = [axes]

    fig.suptitle('üîç Confusion Matrices - Cancer Readmission Prediction',
                 fontsize=16, fontweight='bold', y=1.02)

    for idx, (model_name, pred_df) in enumerate(predictions_dict.items()):
        # Convert to pandas
        pred_pd = pred_df.select(target_col, 'prediction').toPandas()

        y_true = pred_pd[target_col].values
        y_pred = pred_pd['prediction'].values

        # Calculate confusion matrix
        cm = confusion_matrix(y_true, y_pred)

        # Plot
        ax = axes[idx]
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   ax=ax, cbar=True, square=True,
                   annot_kws={'size': 16, 'weight': 'bold'})

        ax.set_title(f'{model_name}', fontsize=14, fontweight='bold')
        ax.set_xlabel('Predicted', fontsize=12, fontweight='bold')
        ax.set_ylabel('Actual', fontsize=12, fontweight='bold')
        ax.set_xticklabels(['No Readmit', 'Readmit'])
        ax.set_yticklabels(['No Readmit', 'Readmit'])

        # Add metrics text
        tn, fp, fn, tp = cm.ravel()
        accuracy = (tp + tn) / (tp + tn + fp + fn)
        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0

        metrics_text = f'Accuracy: {accuracy:.3f}\nSensitivity: {sensitivity:.3f}\nSpecificity: {specificity:.3f}'
        ax.text(0.02, 0.98, metrics_text, transform=ax.transAxes,
               verticalalignment='top', bbox=dict(boxstyle='round',
               facecolor='wheat', alpha=0.8), fontsize=10)

    plt.tight_layout()
    plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("‚úÖ Saved: confusion_matrices.png")

# ============================================================================
# VISUALIZATION 5: FEATURE IMPORTANCE
# ============================================================================

def plot_feature_importance(model, feature_names, model_name):
    """Plot feature importance for tree-based models"""

    try:
        # Get feature importance
        if hasattr(model, 'featureImportances'):
            importances = model.featureImportances.toArray()
        else:
            print(f"‚ö†Ô∏è  {model_name} doesn't support feature importance")
            return

        # Create dataframe
        feat_imp = pd.DataFrame({
            'feature': feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False).head(20)

        # Plot
        plt.figure(figsize=(12, 10))
        colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(feat_imp)))

        plt.barh(range(len(feat_imp)), feat_imp['importance'], color=colors, edgecolor='black')
        plt.yticks(range(len(feat_imp)), feat_imp['feature'])
        plt.xlabel('Importance Score', fontsize=14, fontweight='bold')
        plt.ylabel('Features', fontsize=14, fontweight='bold')
        plt.title(f'üéØ Top 20 Features - {model_name}',
                 fontsize=16, fontweight='bold')
        plt.gca().invert_yaxis()
        plt.grid(axis='x', alpha=0.3)

        plt.tight_layout()
        filename = f'feature_importance_{model_name.replace(" ", "_").lower()}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.show()

        print(f"‚úÖ Saved: {filename}")

    except Exception as e:
        print(f"‚ùå Error plotting feature importance: {e}")

# ============================================================================
# VISUALIZATION 6: RISK STRATIFICATION
# ============================================================================

def plot_risk_stratification(predictions, target_col):
    """Visualize patient risk stratification"""

    # Convert to pandas
    pred_pd = predictions.select(target_col, 'probability', 'prediction').toPandas()

    # Get predicted probabilities
    pred_pd['risk_score'] = pred_pd['probability'].apply(lambda x: float(x[1]))

    # Create risk groups
    pred_pd['risk_group'] = pd.cut(pred_pd['risk_score'],
                                    bins=[0, 0.33, 0.67, 1.0],
                                    labels=['Low Risk', 'Medium Risk', 'High Risk'])

    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('üìä Patient Risk Stratification Analysis',
                 fontsize=16, fontweight='bold', y=0.995)

    # Subplot 1: Risk Score Distribution
    ax = axes[0, 0]
    ax.hist(pred_pd['risk_score'], bins=50, color='#3498db', alpha=0.7, edgecolor='black')
    ax.axvline(0.33, color='green', linestyle='--', linewidth=2, label='Low/Medium threshold')
    ax.axvline(0.67, color='orange', linestyle='--', linewidth=2, label='Medium/High threshold')
    ax.set_xlabel('Predicted Risk Score', fontweight='bold')
    ax.set_ylabel('Number of Patients', fontweight='bold')
    ax.set_title('Distribution of Risk Scores', fontweight='bold')
    ax.legend()
    ax.grid(axis='y', alpha=0.3)

    # Subplot 2: Risk Groups
    ax = axes[0, 1]
    risk_counts = pred_pd['risk_group'].value_counts()
    colors_risk = ['#2ecc71', '#f39c12', '#e74c3c']
    wedges, texts, autotexts = ax.pie(risk_counts, labels=risk_counts.index,
                                       autopct='%1.1f%%', colors=colors_risk,
                                       startangle=90, textprops={'fontsize': 12, 'weight': 'bold'})
    ax.set_title('Distribution of Risk Groups', fontweight='bold')

    # Subplot 3: Actual Readmission by Risk Group
    ax = axes[1, 0]
    risk_actual = pred_pd.groupby('risk_group')[target_col].agg(['sum', 'count'])
    risk_actual['rate'] = (risk_actual['sum'] / risk_actual['count']) * 100

    bars = ax.bar(range(len(risk_actual)), risk_actual['rate'],
                  color=colors_risk, alpha=0.7, edgecolor='black')
    ax.set_xticks(range(len(risk_actual)))
    ax.set_xticklabels(risk_actual.index)
    ax.set_ylabel('Actual Readmission Rate (%)', fontweight='bold')
    ax.set_title('Actual Readmission Rate by Risk Group', fontweight='bold')
    ax.grid(axis='y', alpha=0.3)

    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.1f}%',
                ha='center', va='bottom', fontweight='bold')

    # Subplot 4: Calibration
    ax = axes[1, 1]

    # Group by predicted probability bins
    pred_pd['prob_bin'] = pd.cut(pred_pd['risk_score'], bins=10)
    calibration = pred_pd.groupby('prob_bin').agg({
        'risk_score': 'mean',
        target_col: 'mean'
    }).dropna()

    ax.plot(calibration['risk_score'], calibration[target_col],
           marker='o', markersize=10, linewidth=3, color='#3498db', label='Model')
    ax.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Perfect Calibration', alpha=0.5)
    ax.set_xlabel('Predicted Probability', fontweight='bold')
    ax.set_ylabel('Observed Frequency', fontweight='bold')
    ax.set_title('Calibration Curve', fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_xlim([0, 1])
    ax.set_ylim([0, 1])

    plt.tight_layout()
    plt.savefig('risk_stratification.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("‚úÖ Saved: risk_stratification.png")

    # Print summary statistics
    print("\nüìä Risk Stratification Summary:")
    print("="*60)
    for risk_group in ['Low Risk', 'Medium Risk', 'High Risk']:
        if risk_group in pred_pd['risk_group'].values:
            group_data = pred_pd[pred_pd['risk_group'] == risk_group]
            n_patients = len(group_data)
            readmit_rate = (group_data[target_col].sum() / n_patients) * 100
            print(f"{risk_group:12s}: {n_patients:4d} patients ({readmit_rate:.1f}% readmitted)")

# ============================================================================
# MAIN VISUALIZATION FUNCTION
# ============================================================================

def create_all_visualizations(models, predictions, results, training_times,
                             feature_names, target_col):
    """Generate all visualizations"""

    print("\n" + "="*80)
    print("üìä GENERATING VISUALIZATIONS")
    print("="*80)

    # 1. Model comparison
    print("\nüìà Creating model comparison charts...")
    plot_model_comparison(results, training_times)

    # 2. ROC curves
    print("\nüìà Creating ROC curves...")
    plot_roc_curves(predictions, target_col)

    # 3. Precision-Recall curves
    print("\nüìà Creating precision-recall curves...")
    plot_precision_recall_curves(predictions, target_col)

    # 4. Confusion matrices
    print("\nüìà Creating confusion matrices...")
    plot_confusion_matrices(predictions, target_col)

    # 5. Feature importance (for tree models)
    print("\nüìà Creating feature importance plots...")
    for model_name, model in models.items():
        if 'Forest' in model_name or 'Boosted' in model_name:
            plot_feature_importance(model, feature_names, model_name)

    # 6. Risk stratification (using best model)
    print("\nüìà Creating risk stratification analysis...")
    best_model = max(results.keys(), key=lambda k: results[k]['auc'])
    plot_risk_stratification(predictions[best_model], target_col)

    print("\n" + "="*80)
    print("‚úÖ ALL VISUALIZATIONS COMPLETED!")
    print("="*80)
    print("\nGenerated files:")
    print("  ‚Ä¢ model_comparison.png")
    print("  ‚Ä¢ roc_curves.png")
    print("  ‚Ä¢ precision_recall_curves.png")
    print("  ‚Ä¢ confusion_matrices.png")
    print("  ‚Ä¢ feature_importance_*.png")
    print("  ‚Ä¢ risk_stratification.png")

# ============================================================================
# EXAMPLE USAGE (run after main pipeline)
# ============================================================================

"""
# After running the main pipeline, call:

create_all_visualizations(
    models=models,                    # Dictionary of trained models
    predictions=predictions,          # Dictionary of predictions
    results=results,                  # Dictionary of evaluation results
    training_times=training_times,    # Dictionary of training times
    feature_names=feature_cols,       # List of feature names
    target_col=config.TARGET_COLUMN   # Name of target column
)
"""

def plot_risk_stratification(predictions, target_col):
    """Visualize patient risk stratification - FIXED VERSION"""


    pred_pd = predictions.select(target_col, 'probability', 'prediction').toPandas()


    pred_pd['risk_score'] = pred_pd['probability'].apply(
        lambda x: float(x[1]) if hasattr(x, '__getitem__') else float(x[1])
    )


    pred_pd['risk_group'] = pd.cut(pred_pd['risk_score'],
                                    bins=[0, 0.33, 0.67, 1.0],
                                    labels=['Low Risk', 'Medium Risk', 'High Risk'])

# Add this to the end of your main() function or run in a new cell
print("\n" + "="*80)
print("üé® GENERATING VISUALIZATIONS")
print("="*80)

# Create all visualizations (this will generate 6+ plots)
create_all_visualizations(
    models=models,                    # From main pipeline
    predictions=predictions,          # From main pipeline
    results=results,                  # From main pipeline
    training_times=training_times,    # From main pipeline
    feature_names=feature_cols,       # From main pipeline
    target_col=config.TARGET_COLUMN   # From config
)

print("\nüéâ VISUALIZATION SUITE COMPLETE!")
print("üìÅ Check your working directory for PNG files")

# ============================================================================
# MAIN PIPELINE
# ============================================================================

def main():
    """Execute complete cancer readmission prediction pipeline"""

    start_time = time.time()

    try:
        # Initialize
        config = Config()
        spark = initialize_spark()

        # Load data
        df = load_and_validate_data(spark, config.DATA_PATH)

        # Feature engineering
        df = engineer_cancer_features(df, config)

        # Prepare ML data
        train_data, test_data, feature_cols, prep_model = prepare_ml_data(df, config)

        # Train models
        models, predictions, training_times = train_models(train_data, test_data, config)

        # Evaluate
        results = evaluate_models(predictions, config)

        # Compare
        best_model = compare_models(results, training_times)

        # === ADD VISUALIZATION BLOCK HERE ===
        print("\n" + "="*80)
        print("üé® GENERATING VISUALIZATIONS")
        print("="*80)

        create_all_visualizations(
            models=models,
            predictions=predictions,
            results=results,
            training_times=training_times,
            feature_names=feature_cols,
            target_col=config.TARGET_COLUMN
        )
        # ====================================

        # Summary
        total_time = time.time() - start_time
        print(f"\n{'='*80}")
        print(f"‚úÖ PIPELINE + VISUALIZATIONS COMPLETED SUCCESSFULLY!")
        print(f"{'='*80}")
        print(f"   Total runtime: {total_time:.2f} seconds")
        print(f"   Best model: {best_model}")
        print(f"   Best AUC: {results[best_model]['auc']:.4f}")
        print(f"\nüí° Next Steps:")
        print(f"   1. Review feature importance")
        print(f"   2. Analyze misclassified cases")
        print(f"   3. Tune hyperparameters")
        print(f"   4. Validate on external dataset")
        print(f"   5. Deploy for real-time predictions")

    except Exception as e:
        print(f"\n‚ùå Pipeline failed: {e}")
        import traceback
        traceback.print_exc()

    finally:
        spark.stop()
        print(f"\nüõë Spark session stopped")

if __name__ == "__main__":
    main()

